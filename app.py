import os
import re
import time
import requests
import streamlit as st
import pandas as pd
import numpy as np
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from datetime import datetime, timedelta, timezone

# -----------------------------
# ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="YouTube í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ê¸°",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# -----------------------------
# ìƒìˆ˜ / ì „ì—­ íŒ¨í„´
# -----------------------------
BASE_URL = "https://www.googleapis.com/youtube/v3"
KST = timezone(timedelta(hours=9))

# ë¶ˆìš©ì–´(ë¶„ì„ì— ì˜ë¯¸ê°€ ì ì€ ë‹¨ì–´ë“¤ ì œê±°)
DEFAULT_STOPWORDS = {
    "ì˜ìƒ", "ë™ì˜ìƒ", "ë¸Œì´ë¡œê·¸", "vlog",
    "the", "a", "to", "of", "in", "on", "for", "and", "is", "are", "with", "from",
    "í•œ", "ê²ƒ", "ìˆ˜", "ì´", "ê·¸", "ì €", "ë°", "ë“±", "ë•Œ", "ë•Œë¬¸",
    "ì˜¤ëŠ˜", "í•˜ë£¨", "ì¼ìƒ",
    "ì±„ë„", "ìœ íŠœë¸Œ", "youtube",
    "shorts", "short",
    "ê³µì‹", "official", "full",
    "2023", "2024", "2025"
}

# í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ í† í° ì¶”ì¶œìš© ì •ê·œì‹
TOKEN_PATTERN = re.compile(r"[A-Za-zê°€-í£]+")

# -----------------------------
# API í‚¤ ë¡œë”© ìœ í‹¸
# -----------------------------
def load_api_key():
    """
    Streamlit secrets > í™˜ê²½ë³€ìˆ˜(YOUTUBE_API_KEY) ìˆœì„œë¡œ ë¡œë“œ.
    ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.
    """
    key_from_secrets = st.secrets.get("YOUTUBE_API_KEY", None)
    if key_from_secrets:
        return key_from_secrets
    return os.getenv("YOUTUBE_API_KEY", "")

API_KEY = load_api_key()


# -----------------------------
# YouTube API í˜¸ì¶œ ìœ í‹¸
# -----------------------------
def yt_get(path, params, sleep=0.0):
    """
    YouTube Data API GET ë˜í¼.
    - API í‚¤ ì£¼ì…
    - ê°„ë‹¨ ì¿¼í„° ë³´í˜¸ìš© sleep
    - ì˜¤ë¥˜ì‹œ RuntimeErrorë¡œ ì˜¬ë¦¼
    """
    if not API_KEY:
        raise RuntimeError(
            "API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ 'Manage app â†’ Secrets'ì— "
            'YOUTUBE_API_KEY = "ì‹¤ì œí‚¤" í˜•ì‹ìœ¼ë¡œ ë“±ë¡í•˜ê±°ë‚˜, '
            "ë¡œì»¬ì—ì„œëŠ” OS í™˜ê²½ë³€ìˆ˜ YOUTUBE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”."
        )
    final_params = dict(params)
    final_params["key"] = API_KEY
    url = f"{BASE_URL}/{path}"

    r = requests.get(url, params=final_params, timeout=30)
    if sleep:
        time.sleep(sleep)

    if r.status_code != 200:
        raise RuntimeError(f"API ì˜¤ë¥˜ {r.status_code}: {r.text}")
    return r.json()


def youtube_search(keyword, published_after, published_before,
                   region_code, max_results=50):
    """
    ê²€ìƒ‰(search.list)ìœ¼ë¡œ videoId ëª©ë¡ ìˆ˜ì§‘.
    keyword: ê²€ìƒ‰ì–´
    published_after/before: ISO8601 UTC ì‹œê°„ ë¬¸ìì—´
    region_code: 'KR', 'US' ë“±ì˜ ì§€ì—­ ì½”ë“œ (ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥)
    max_results: ìµœì¢…ì ìœ¼ë¡œ ê°€ì ¸ì˜¬ ìµœëŒ€ ë¹„ë””ì˜¤ ìˆ˜
    """
    ids = []
    fetched = 0
    next_page_token = None

    while fetched < max_results:
        page_size = min(50, max_results - fetched)

        query_params = {
            "part": "id",
            "type": "video",
            "q": keyword,
            "publishedAfter": published_after,
            "publishedBefore": published_before,
            "maxResults": page_size,
            "order": "relevance",
        }
        # regionCodeëŠ” ì„ íƒê°’ì´ì§€ë§Œ, ë¹ˆ ë¬¸ìì—´ì´ë©´ ì—ëŸ¬ ì¤„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¡°ê±´ë¶€ ì¶”ê°€
        if region_code:
            query_params["regionCode"] = region_code

        # pageTokenì´ ìˆìœ¼ë©´ ì¶”ê°€
        if next_page_token:
            query_params["pageToken"] = next_page_token

        data = yt_get("search", query_params, sleep=0.05)

        items = data.get("items", [])
        for item in items:
            vid = item.get("id", {}).get("videoId")
            if vid:
                ids.append(vid)

        fetched += len(items)
        next_page_token = data.get("nextPageToken")

        # ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ê±°ë‚˜ ì´ë²ˆ í˜ì´ì§€ì—ì„œ ì•„ë¬´ ê²ƒë„ ëª» ê°€ì ¸ì™”ìœ¼ë©´ ì¢…ë£Œ
        if (not next_page_token) or (len(items) == 0):
            break

    # dict.fromkeys: ì…ë ¥ ìˆœì„œë¥¼ ìœ ì§€í•˜ë©´ì„œ ì¤‘ë³µ ì œê±°
    return list(dict.fromkeys(ids))


def youtube_videos_stats(video_ids):
    """
    videos.list ë¡œ ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°/í†µê³„ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜.
    - title, description, channelTitle, publishedAt
    - viewCount, likeCount, commentCount
    - ER(%) = (like+comment)/view * 100
    """
    rows = []

    for i in range(0, len(video_ids), 50):
        chunk = ",".join(video_ids[i:i+50])
        data = yt_get(
            "videos",
            {
                "part": "snippet,statistics,contentDetails",
                "id": chunk,
            },
            sleep=0.05,
        )

        for it in data.get("items", []):
            s = it.get("snippet", {})
            stats = it.get("statistics", {})
            row = {
                "videoId": it.get("id"),
                "title": s.get("title", ""),
                "description": s.get("description", ""),
                "channelTitle": s.get("channelTitle", ""),
                "publishedAt": s.get("publishedAt", ""),
                "viewCount": int(stats.get("viewCount", 0) or 0),
                "likeCount": int(stats.get("likeCount", 0) or 0),
                "commentCount": int(stats.get("commentCount", 0) or 0),
            }
            rows.append(row)

    df = pd.DataFrame(rows)

    if not df.empty:
        # ë¬¸ìì—´ì„ ì‹œê³„ì—´ë¡œ ë³€í™˜
        df["publishedAt"] = pd.to_datetime(df["publishedAt"], errors="coerce")

        # ER (Engagement Rate)
        df["ER(%)"] = np.where(
            df["viewCount"] > 0,
            (df["likeCount"] + df["commentCount"]) / df["viewCount"] * 100.0,
            0.0,
        ).round(3)

    return df


# -----------------------------
# í…ìŠ¤íŠ¸ ì²˜ë¦¬ / í‚¤ì›Œë“œ ë¶„ì„
# -----------------------------
def tokenize(text: str):
    """
    ì œëª©+ì„¤ëª…ì—ì„œ í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ë§Œ ì¶”ì¶œí•˜ê³ ,
    ë¶ˆìš©ì–´/ê¸¸ì´<2 ë‹¨ì–´ ì œê±°.
    """
    tokens = TOKEN_PATTERN.findall(text.lower())
    return [
        t for t in tokens
        if t not in DEFAULT_STOPWORDS and len(t) >= 2
    ]


def keywords_from_df(df, topn=100):
    """
    DataFrameì—ì„œ title+descriptionì„ í•©ì³ í† í°í™”í•˜ê³ 
    ìƒìœ„ ë¹ˆë„ í‚¤ì›Œë“œ (topnê°œ) ë°˜í™˜.
    """
    corpus = []
    for _, row in df.iterrows():
        title_txt = row.get("title", "")
        desc_txt = row.get("description", "")
        corpus.extend(tokenize(f"{title_txt} {desc_txt}"))

    counter = Counter(corpus)
    return counter.most_common(topn)


def draw_wordcloud(freqs, font_path=None):
    """
    ë‹¨ì–´ ë¹ˆë„(freqs)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ê·¸ë ¤ì„œ matplotlib Figure ë°˜í™˜.
    font_path: í•œê¸€ í°íŠ¸ ê²½ë¡œ í•„ìš” ì‹œ ì§€ì •.
    """
    wc = WordCloud(
        width=900,
        height=500,
        background_color="white",
        font_path=font_path if font_path else None,
        collocations=False
    )
    wc.generate_from_frequencies(dict(freqs))

    fig = plt.figure(figsize=(9, 5))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    return fig


# -----------------------------
# UI - í—¤ë”
# -----------------------------
st.title("ğŸ“ˆ ìœ íŠœë¸Œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ê¸°")
st.caption("í‚¤ì›Œë“œ/ê¸°ê°„ìœ¼ë¡œ ìƒìœ„ ë™ì˜ìƒì„ ìˆ˜ì§‘í•´ ì›Œë“œí´ë¼ìš°ë“œì™€ ì°¸ì—¬ìœ¨(ER)ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

# -----------------------------
# UI - ì‚¬ì´ë“œë°” ì…ë ¥
# -----------------------------
with st.sidebar:
    st.subheader("ê²€ìƒ‰ ì„¤ì •")

    keyword = st.text_input(
        "í‚¤ì›Œë“œ (ì˜ˆ: ë¸Œì´ë¡œê·¸ / ì˜ì–´ ê°€ëŠ¥)",
        value="ë¸Œì´ë¡œê·¸"
    )

    days = st.number_input(
        "ìµœê·¼ Nì¼",
        min_value=1,
        max_value=365,
        value=30,
        step=1
    )

    max_results = st.slider(
        "ìˆ˜ì§‘í•  ì˜ìƒ ìˆ˜",
        min_value=10,
        max_value=200,
        value=80,
        step=10
    )

    region_code = st.text_input(
        "ì§€ì—­ ì½”ë“œ (ì„ íƒ, KR/US/JP ë“±)",
        value="KR"
    ).strip().upper()

    font_path = st.text_input(
        "ì›Œë“œí´ë¼ìš°ë“œ í•œê¸€ í°íŠ¸ ê²½ë¡œ(ì„ íƒ)",
        value=""
    )

    st.markdown("---")

    # API í‚¤ ìƒíƒœ í‘œì‹œ
    if API_KEY:
        st.success("YouTube API í‚¤ ë¡œë“œ ì™„ë£Œ")
    else:
        st.error("YouTube API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("""
**Streamlit Cloud > Manage app > Secrets** ì— ì•„ë˜ì²˜ëŸ¼ ë“±ë¡í•˜ì„¸ìš”:

```toml
YOUTUBE_API_KEY = "ì—¬ê¸°ì—_ì‹¤ì œ_API_KEY"
